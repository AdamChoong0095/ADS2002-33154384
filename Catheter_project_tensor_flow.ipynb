{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AdamChoong0095/ADS2002-33154384/blob/main/Catheter_project_tensor_flow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hfzGdcGZL5SX"
      },
      "source": [
        "# Catheater project (Neural Networks component)\n",
        "\n",
        "Contributors:\n",
        "Adam Choong\n",
        "Louise Childs\n",
        "Isaac Woods\n",
        "Fengzhe Yang\n",
        "\n",
        "The goal of this project is to determine whether CVC or NGC or ETT catheaters are \"normally\" placed or not. Hence, the approach taken will be a binary classificiation approach. We will be comparing neural network model configurations based on various metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sUuFBBN2MtUD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fff6e5e3-1af2-40a5-ec3a-33e6ed8a04d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import os\n",
        "import ast\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, roc_auc_score\n",
        "RS=42#set random seed consistent do not changeb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train=pd.read_csv('/content/drive/MyDrive/ADS2002-Catheter-Team1/ranzcr-clip-catheter-line-classification/train.csv')\n",
        "train_annots=pd.read_csv('/content/drive/MyDrive/ADS2002-Catheter-Team1/ranzcr-clip-catheter-line-classification/train_annotations.csv')"
      ],
      "metadata": {
        "id": "RdbaWUaU9u01"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5Lwuh1_QLzQ"
      },
      "source": [
        "Since the entire dataset is too large and we need to be mindful of the RAM capacity, there needs to be a function in place to partially read a random sample of the dataset. We also need to organise the dataframes in such as way that it contains the images as the \"feature variable\" and the outcomes as the labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfNLHU9O9Oyn"
      },
      "source": [
        "## Handling the csv files and directories\n",
        "A handful of useful functions will be defined below. Their main purposes will be:\n",
        "* Cleaning the dataframe so that it includes only the instances with one outcome and possibly one annotation for each catheter type\n",
        "* Forming the appropriate directory structures for ResNet and DenseNet and other models\n",
        "* Setting file labels on dataframes\n",
        "* Reading images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oDr-TUM_gqgI"
      },
      "outputs": [],
      "source": [
        "def set_files_on_dataframe(df,tag='StudyInstanceUID'):\n",
        "  '''\n",
        "  df: target data frame\n",
        "  tag: StudyInstanceUID\n",
        "  '''\n",
        "  if 'image_file' not in df.columns:\n",
        "    df['image_file']=''\n",
        "  for i,row in df.iterrows():\n",
        "    if '.jpg' not in row[tag]:\n",
        "      path=row[tag]+'.jpg'\n",
        "      df._set_value(i,'image_file',path)\n",
        "    elif '.jpg' in row[tag]:\n",
        "      path=row[tag]\n",
        "      df._set_value(i,'image_file',path)\n",
        "  return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MspHD0MF9Oyo"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "#creates directories for training,validating and testing\n",
        "def copy_files(destination_directory,source_directory,image_files):\n",
        "  '''\n",
        "  image files argument is a list of image files to move\n",
        "  '''\n",
        "  # Iterate through the image files and move them to the destination directory\n",
        "  for image_file in image_files:\n",
        "      source_path = os.path.join(source_directory,image_file)\n",
        "      destination_path = os.path.join(destination_directory,image_file)\n",
        "      # Check if the destination file already exists, and if it does, rename it to avoid overwriting\n",
        "      if os.path.exists(destination_path):\n",
        "          base, extension = os.path.splitext(image_file)\n",
        "          count = 1\n",
        "          while os.path.exists(destination_path):\n",
        "              new_filename = f\"{base}_{count}{extension}\"\n",
        "              destination_path = os.path.join(destination_directory, new_filename)\n",
        "              count += 1\n",
        "      # Move the image file to the destination directory\n",
        "      if os.path.exists(destination_path):\n",
        "        print(f\"File '{image_file}' already exists in the destination directory. Skipping...\")\n",
        "      else:\n",
        "        # Move the image file to the destination directory\n",
        "        shutil.copy(source_path, destination_path)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TMcqMIY5-A9F"
      },
      "outputs": [],
      "source": [
        "def organise_dir(origin,train_dir,val_dir,test_dir,cath_type,sample):\n",
        "  '''\n",
        "  args\n",
        "  -origin: source file\n",
        "  -train/test/val dir: location of folders containing files for testing training, etc.\n",
        "  -cath_typle: catheter type we test on\n",
        "  -sample: sample data frame we test on, must only have one type of catheter considered\n",
        "  '''\n",
        "  train_validate,test = train_test_split(sample, test_size=0.1,random_state=RS)\n",
        "  train,validate = train_test_split(train_validate, test_size=0.11,random_state=RS)\n",
        "  '''\n",
        "  splits data too\n",
        "  must match certain directory structure to work\n",
        "  dataframe must match certain structure to work see above\n",
        "  '''\n",
        "  train_normal=train[train[cath_type+' - Normal'] == 1]\n",
        "  train_abnormal=train[train[cath_type+' - Abnormal'] == 1]\n",
        "  train_borderline=train[train[cath_type+' - Borderline'] == 1]\n",
        "  validate_normal=validate[validate[cath_type+' - Normal'] == 1]\n",
        "  validate_abnormal=validate[validate[cath_type+' - Abnormal'] == 1]\n",
        "  validate_borderline=validate[validate[cath_type+' - Borderline'] == 1]\n",
        "  test_normal=test[test[cath_type+' - Normal'] == 1]\n",
        "  test_abnormal=test[test[cath_type+' - Abnormal'] == 1]\n",
        "  test_borderline=test[test[cath_type+' - Borderline'] == 1]\n",
        "  train_norm_dir=train_dir+'/Normal'\n",
        "  train_border_dir=train_dir+'/Borderline'\n",
        "  train_ab_dir=train_dir+'/Abnormal'\n",
        "  val_norm_dir=val_dir+'/Normal'\n",
        "  val_border_dir=val_dir+'/Borderline'\n",
        "  val_ab_dir=val_dir+'/Abnormal'\n",
        "  test_norm_dir=test_dir+'/Normal'\n",
        "  test_border_dir=test_dir+'/Borderline'\n",
        "  test_ab_dir=test_dir+'/Abnormal'\n",
        "  train_list_normal=train_normal['image_file'].tolist()\n",
        "  train_list_abnormal=train_abnormal['image_file'].tolist()\n",
        "  train_list_borderline=train_borderline['image_file'].tolist()\n",
        "  val_list_normal=validate_normal['image_file'].tolist()\n",
        "  val_list_abnormal=validate_abnormal['image_file'].tolist()\n",
        "  val_list_borderline=validate_borderline['image_file'].tolist()\n",
        "  test_list_normal=test_normal['image_file'].tolist()\n",
        "  test_list_abnormal=test_abnormal['image_file'].tolist()\n",
        "  test_list_borderline=test_borderline['image_file'].tolist()\n",
        "  copy_files(destination_directory=test_border_dir,source_directory=origin,image_files=test_list_borderline)\n",
        "  copy_files(destination_directory=test_norm_dir,source_directory=origin,image_files=test_list_normal)\n",
        "  copy_files(destination_directory=test_ab_dir,source_directory=origin,image_files=test_list_abnormal)\n",
        "  copy_files(destination_directory=train_border_dir,source_directory=origin,image_files=train_list_borderline)\n",
        "  copy_files(destination_directory=train_norm_dir,source_directory=origin,image_files=train_list_normal)\n",
        "  copy_files(destination_directory=train_ab_dir,source_directory=origin,image_files=train_list_abnormal)\n",
        "  copy_files(destination_directory=val_border_dir,source_directory=origin,image_files=val_list_borderline)\n",
        "  copy_files(destination_directory=val_norm_dir,source_directory=origin,image_files=val_list_normal)\n",
        "  copy_files(destination_directory=val_ab_dir,source_directory=origin,image_files=val_list_abnormal)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DSa9IPXwcVqy"
      },
      "outputs": [],
      "source": [
        "def clean_dataframe(df,cath_type):\n",
        "    '''\n",
        "    only runs for train, not train annotations\n",
        "    '''\n",
        "    if cath_type == 'CVC' or cath_type == 'ETT':\n",
        "        dataframe=df[['StudyInstanceUID',cath_type+' - Abnormal',cath_type+' - Normal',cath_type+' - Borderline','image_file']]\n",
        "        dataframe=dataframe.drop(dataframe[(dataframe[cath_type+' - Abnormal'] == 0) & (dataframe[cath_type+' - Normal'] == 0) & (dataframe[cath_type+' - Borderline'] == 0)].index)\n",
        "        dataframe=dataframe.drop(dataframe[(dataframe[cath_type+' - Abnormal'] == 1) & (dataframe[cath_type+' - Normal'] == 1)].index)\n",
        "        dataframe=dataframe.drop(dataframe[(dataframe[cath_type+' - Borderline'] == 1) & (dataframe[cath_type+' - Normal'] == 1)].index)\n",
        "        dataframe=dataframe.drop(dataframe[(dataframe[cath_type+' - Abnormal'] == 1) & (dataframe[cath_type+' - Borderline'] == 1)].index)\n",
        "    elif cath_type == 'NGT':\n",
        "        dataframe=df[['StudyInstanceUID','NGT - Abnormal','NGT - Normal','NGT - Borderline','NGT - Incompletely Imaged','image_file']]\n",
        "        dataframe=dataframe.drop(dataframe[(dataframe['NGT - Abnormal'] == 0) & (dataframe['NGT - Normal'] == 0) & (dataframe['NGT - Borderline'] == 0) & (dataframe['NGT - Incompletely Imaged']==0)].index)\n",
        "        dataframe=dataframe.drop(dataframe[(dataframe['NGT - Incompletely Imaged']==1)].index)\n",
        "        dataframe=dataframe.drop(dataframe[(dataframe['NGT - Abnormal'] == 1) & (dataframe['NGT - Normal'] == 1)].index)\n",
        "        dataframe=dataframe.drop(dataframe[(dataframe['NGT - Borderline'] == 1) & (dataframe['NGT - Normal'] == 1)].index)\n",
        "        dataframe=dataframe.drop(dataframe[(dataframe['NGT - Abnormal'] == 1) & (dataframe['NGT - Borderline'] == 1)].index)\n",
        "    return dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rumhvtpn_7SV"
      },
      "outputs": [],
      "source": [
        "def image_reader(directory,file_name):\n",
        "  path=directory+'/'+file_name\n",
        "  img=cv2.imread(path)\n",
        "  img=cv2.resize(img,dsize=(32,32))\n",
        "  return img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QcA71NmsLWDX"
      },
      "outputs": [],
      "source": [
        "def set_image_on_df(df,dir):\n",
        "    '''\n",
        "    works as long as there is a StudyInstanceUID column\n",
        "    '''\n",
        "    df['image']=''\n",
        "    for i in range(0,len(df)):\n",
        "        image=image_reader(dir,df.iloc[i]['image_file'])\n",
        "        image=image.astype('float')\n",
        "        df.at[i, 'image'] = image\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l5fTityfgScv"
      },
      "outputs": [],
      "source": [
        "set_files_on_dataframe(train)\n",
        "ett=clean_dataframe(train,'ETT')\n",
        "cvc=clean_dataframe(train,'CVC')\n",
        "ngt=clean_dataframe(train,'NGT')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6BhK7Qm88es2"
      },
      "source": [
        "## Reading the data\n",
        "We need to manipulate our dataset so it fulfils the mentioned criteria\n",
        "* Multiclassification\n",
        "* Relevant images only considered\n",
        "* Feature extraction (highlighting annotations to increase pixel intensity)\n",
        "* Well balanced variations\n",
        "\n",
        "We will be using all images first but extending scalability will involve using only annotations\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_annots=set_files_on_dataframe(train_annots)"
      ],
      "metadata": {
        "id": "JIamqab6-z4K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I2yxcKXY9Oyr"
      },
      "outputs": [],
      "source": [
        "#source: https://www.kaggle.com/code/ihelon/catheter-position-exploratory-data-analysis?fbclid=IwAR1rhwS0ZMuVUkkUQMeP6TumSQFzpHMhypeCjb0IuVJcHCWVHtYVaKpwOjA\n",
        "def plot_image_with_annotations(row_ind,df_annot,BASE_DIR):\n",
        "    row = df_annot.iloc[row_ind]\n",
        "    image_path = BASE_DIR+ \"/\"+row[\"StudyInstanceUID\"] + \".jpg\"\n",
        "    label = row[\"label\"]\n",
        "    data = np.array(ast.literal_eval(row[\"data\"]))\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    image = cv2.imread(image_path)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    plt.imshow(image)\n",
        "    plt.scatter(data[:, 0], data[:, 1])\n",
        "    plt.suptitle(label, fontsize=15)\n",
        "\n",
        "def visualize_annotations(file_id,BASE_DIR,df_annot):\n",
        "    plt.figure(figsize=(8, 8))\n",
        "    image = cv2.imread(BASE_DIR+ \"/\"+file_id+'.jpg')\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    plt.imshow(image)\n",
        "\n",
        "    df_patient = df_annot.loc[df_annot[\"StudyInstanceUID\"] == file_id]\n",
        "\n",
        "    if df_patient.shape[0]:\n",
        "        labels = df_patient[\"label\"].values.tolist()\n",
        "        lines = df_patient[\"data\"].apply(ast.literal_eval).values.tolist()\n",
        "\n",
        "        for line, label in zip(lines, labels):\n",
        "            line = np.asarray(line)\n",
        "            plt.scatter(line[:, 0], line[:, 1], s=40, label=label)\n",
        "\n",
        "        plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0, prop={'size': 20})\n",
        "\n",
        "    plt.tick_params(axis=\"x\", labelsize=15)\n",
        "    plt.tick_params(axis=\"y\", labelsize=15)\n",
        "    plt.show()\n",
        "\n",
        "def save_annot_plot(dest,row_ind,df_annot,source):\n",
        "  row = df_annot.iloc[row_ind]\n",
        "  plot_image_with_annotations(row_ind,df_annot,source)\n",
        "  dest_path=dest+'/'+row[\"StudyInstanceUID\"] + \".jpg\"\n",
        "  if os.path.exists(dest_path):\n",
        "    pass\n",
        "  else:\n",
        "    plt.savefig(dest_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0dhVlBsA9Oys"
      },
      "source": [
        "## Balancing datasets\n",
        "There are too many normal images (see EDA brief overview). So we need to make sure there is a balance of the types of catheter placements to prevent meaningless results from being produced. Sampling using SMOTE or ADASYN requires tabular data in our dataframes for the `X` or feature space but these values are all array representations of image data. An easy way to fix this may be to use only `y` and consider `X` as a dummy column. Let's try both methods to see which is better for our problem."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "def encoder(outcomes,cath_type):\n",
        "  '''\n",
        "  works only with train file\n",
        "  '''\n",
        "  outcomes['Outcomes']=''\n",
        "  for i in range(len(outcomes)):\n",
        "    if outcomes.loc[i,cath_type+' - Normal']==1:\n",
        "      outcomes.loc[i,'Outcomes']=cath_type+' - Normal'\n",
        "    elif outcomes.loc[i,cath_type+' - Abnormal']==1:\n",
        "      outcomes.loc[i,'Outcomes']=cath_type+' - Abnormal'\n",
        "    elif outcomes.loc[i,cath_type+' - Borderline']==1:\n",
        "      outcomes.loc[i,'Outcomes']=cath_type+' - Borderline'\n",
        "  outcomes=outcomes.drop([cath_type+' - Normal',cath_type+' - Abnormal',cath_type+' - Borderline'],axis=1)\n",
        "  le=LabelEncoder()\n",
        "  outcomes['Outcomes']=le.fit_transform(outcomes['Outcomes'])\n",
        "  return outcomes\n"
      ],
      "metadata": {
        "id": "8S9Jba4jqV3r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "id": "aztT0tJZ9Oys",
        "outputId": "c69298fb-5df4-4f32-d0da-cbc5b6e4104e"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-0c2b6fd3ef4a>\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Apply ADASYN to the outcome column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0madasyn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mADASYN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msampling_strategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"minority\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0my_resampled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madasyn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_resample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_outcome\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Outcomes\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# Combine resampled outcome with original features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: BaseSampler.fit_resample() missing 1 required positional argument: 'y'"
          ]
        }
      ],
      "source": [
        "from imblearn.over_sampling import SMOTE,ADASYN\n",
        "directory='/content/drive/MyDrive/ADS2002-Catheter-Team1/image_collection'\n",
        "mask = train['image_file'].isin(os.listdir(directory))\n",
        "sample_df = train[mask]\n",
        "sample_df=clean_dataframe(sample_df,'CVC')\n",
        "sample_df.reset_index(inplace=True)\n",
        "sample_df.drop('index',axis=1,inplace=True)\n",
        "encoded=encoder(sample_df,'CVC')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SXQ4_ry89Oyt"
      },
      "outputs": [],
      "source": [
        "mask = train['image_file'].isin(os.listdir(directory))\n",
        "sample_df = train[mask]\n",
        "sample_df=clean_dataframe(sample_df,'CVC')\n",
        "sample_df.reset_index(inplace=True)\n",
        "sample_df.drop('index',axis=1,inplace=True)\n",
        "sample_df=set_image_on_df(sample_df,directory)\n",
        "outcomes=sample_df[[\"CVC - Abnormal\",'CVC - Normal','CVC - Borderline']]\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(image_data,outcomes, test_size=0.2, random_state=RS)\n",
        "X_train = np.array([np.ravel(image) for image in X_train])\n",
        "X_test = np.array([np.ravel(image) for image in X_test])\n",
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0\n",
        "y_train = np.array(y_train)\n",
        "y_test = np.array(y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5dKkL503pxJP"
      },
      "source": [
        "## Moving images to folders\n",
        "The directories need to be separated by training, testing and validating sets with each folder having preclassified images in each of them"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J0f2S9M38Kwl"
      },
      "outputs": [],
      "source": [
        "#check if moved properly\n",
        "def count_files_in_directory(directory):\n",
        "    file_count = 0\n",
        "\n",
        "    # Walk through the directory and its subdirectories\n",
        "    for root, dirs, files in os.walk(directory):\n",
        "        for file in files:\n",
        "            file_count += 1\n",
        "    return file_count"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOXwupLE31yz"
      },
      "source": [
        "## Convolutional Neural Network construction\n",
        "The purpose of this section will be to use ResNet and other models for transfer learning to compare their performances"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tmpyv3lpGPR0"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TKTQVMV6tyRm"
      },
      "outputs": [],
      "source": [
        "def plot_loss(history):\n",
        "  plt.plot(history.history['loss'], label='loss')\n",
        "  plt.plot(history.history['val_loss'], label='val_loss')\n",
        "  plt.ylim([0, 1])\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Error')\n",
        "  plt.legend()\n",
        "  plt.grid(True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "24ePcFiLXVIR"
      },
      "outputs": [],
      "source": [
        "#supervised learning using custom CNN that uses softmax for multiclassification\n",
        "custom = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    tf.keras.layers.Dense(32, activation='relu'),\n",
        "    tf.keras.layers.Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "custom.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "hist=custom.fit(X_train, y_train, epochs=20, batch_size=4, validation_split=0.2)\n",
        "\n",
        "# Evaluate your model\n",
        "test_loss, test_accuracy = custom.evaluate(X_test, y_test)\n",
        "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dLIS34gNuZqx"
      },
      "outputs": [],
      "source": [
        "plot_loss(hist)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Kql3-ORGVAD"
      },
      "outputs": [],
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1.0/255.0,  # Normalize pixel values to [0, 1]\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    'images_split/train',\n",
        "    target_size=(224, 224),  # ResNet-50 input size\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'  # Use 'categorical' for multi-class classification\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O-_gz1hvJVoA"
      },
      "outputs": [],
      "source": [
        "base_model = ResNet50(weights='imagenet', include_top=False)\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)  # Global average pooling\n",
        "x = Dense(256, activation='relu')(x)  # Add a fully connected layer\n",
        "predictions = Dense(3, activation='softmax')(x)  # Output layer\n",
        "model = Model(inputs=base_model.input, outputs=predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XNjBotjlJoCj"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SI-txYn9JsbE"
      },
      "outputs": [],
      "source": [
        "hist=model.fit(train_generator, epochs=3, steps_per_epoch=len(train_generator))\n",
        "plot_loss(hist)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}